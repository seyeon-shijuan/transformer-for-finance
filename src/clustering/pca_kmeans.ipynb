{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# utils.py\n",
    "from utils import *\n",
    "\n",
    "#  차트 설정\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"font.family\"] = 'Malgun Gothic'\n",
    "plt.rcParams[\"font.family\"] = 'AppleGothic'\n",
    "plt.rcParams[\"figure.figsize\"] = (14,4)\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "plt.rcParams[\"axes.grid\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = '../../data/krx_2016.csv'\n",
    "file = '../../data/krx_ta_2016.csv'\n",
    "# file_path = os.path.join(os.path.dirname(__file__), file)\n",
    "all_stocks = pd.read_csv(file, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = df.columns.difference(['Code'])\n",
    "df = df[feature_columns] \n",
    "df = df.replace({0: 0.000001, None: 0.000001}) # 결측치를 매우 작은 수 입력\n",
    "df = df.dropna(axis=0) # 이동평균선 NaN 행 제거\n",
    "# df = df.replace({0: 0.000001, None: 0.000001, 'NaN': 0.000001})\n",
    "pct = df.groupby('Name').pct_change()\n",
    "pct['Name'] = df['Name']\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data = pct.groupby('Name').mean()\n",
    "data = pd.concat([data, pct.groupby('Name').std()], axis=1)\n",
    "# data['Volatility'] = pct.groupby('Name').std() \n",
    "\n",
    "scaler = StandardScaler().fit(data)\n",
    "rescaled_dataset = pd.DataFrame(scaler.fit_transform(data), columns=data.columns, index=data.index)\n",
    "\n",
    "\n",
    "pca_labels = pca_kmeans_clustering(rescaled_dataset,5)\n",
    "cosine_labels = cosine_kmeans_clustering(rescaled_dataset,5)\n",
    "cluster_labels = pd.DataFrame()\n",
    "cluster_labels['pca'] = pca_labels\n",
    "cluster_labels['cosine'] = cosine_labels\n",
    "cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transformation\n",
    "df = all_stocks[['Name', 'Close']].copy()\n",
    "pct = df.groupby('Name').pct_change()\n",
    "pct['Name'] = df['Name']\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['Returns'] = pct.groupby('Name').mean() \n",
    "data['Volatility'] = pct.groupby('Name').std() \n",
    "print(data.head(2))\n",
    "\n",
    "scaler = StandardScaler().fit(data)\n",
    "rescaled_dataset = pd.DataFrame(scaler.fit_transform(data), columns=data.columns, index=data.index)\n",
    "rescaled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 회사의 전체 주식 거래 기간의 30% 이상이 Volume이 0인 경우 해당 회사 데이터 삭제\n",
    "def filter_zero_volume_data(df):\n",
    "    volume_zero_percentage = df.groupby('Name')['Volume'].apply(lambda x: (x == 0).mean())\n",
    "    companies_to_remove = volume_zero_percentage[volume_zero_percentage > 0.3].index\n",
    "    # 조건에 맞는 회사 데이터 삭제\n",
    "    df_filtered = df[~df['Name'].isin(companies_to_remove)]\n",
    "    return df_filtered\n",
    "\n",
    "def standard_scaler(df):\n",
    "    # 전처리\n",
    "    df = filter_zero_volume_data(df)\n",
    "    feature_columns = df.columns.difference(['Code']) # Code 열 제거\n",
    "    df = df[feature_columns] \n",
    "    \n",
    "    # 결측치 처리\n",
    "    df = df.replace({0: 0.000001, None: 0.000001}) \n",
    "    df = df.dropna(axis=0) # 이동평균선 NaN 행 제거\n",
    "    # df = df.fillna(0.000001)\n",
    "\n",
    "    # 변동성을 퍼센트로 변경\n",
    "    pct = df.groupby('Name').pct_change()\n",
    "    pct['Name'] = df['Name']\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "    data = pct.groupby('Name').mean()\n",
    "    data = pd.concat([data, pct.groupby('Name').std()], axis=1)\n",
    "\n",
    "    # scaler\n",
    "    scaler = StandardScaler().fit(data)\n",
    "    rescaled_dataset = pd.DataFrame(scaler.fit_transform(data), columns=data.columns, index=data.index)\n",
    "    return rescaled_dataset\n",
    "\n",
    "# 코사인 유사도 + K-Means 클러스터링\n",
    "def cosine_kmeans_clustering(data, n_clusters):\n",
    "    similarity_matrix = cosine_similarity(data)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42) # random_state : cluster 번호가 변하여 고정\n",
    "    labels = kmeans.fit_predict(similarity_matrix)\n",
    "    return labels\n",
    "\n",
    "# PCA + K-Means 클러스터링\n",
    "def pca_kmeans_clustering(data, n_clusters):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_data = pca.fit_transform(scaled_data)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42) # random_state : cluster 번호가 변하여 고정\n",
    "    labels = kmeans.fit_predict(reduced_data)\n",
    "    return labels\n",
    "\n",
    "# 클러스터링 결과 시각화. 개선 필요\n",
    "def visualize_clusters(data):\n",
    "    plt.scatter(data.values[:, 0], data.values[:, 1], c=data.values[:, 2], cmap='viridis')\n",
    "    plt.title('Cluster Visualization')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.show()\n",
    "\n",
    "# MultiIndex에서 회사별로 클러스터 라벨 추가\n",
    "def add_cluster_labels(df, labels):\n",
    "    df['Cluster'] = labels\n",
    "    return df\n",
    "\n",
    "# n개 미만 클러스터 삭제. 이전 버전.\n",
    "# def filter_clusters(df, n=3):\n",
    "#     cluster_counts = df['Cluster'].value_counts()\n",
    "#     clusters_to_keep = cluster_counts[cluster_counts >= n].index\n",
    "#     df_filtered = df[df['Cluster'].isin(clusters_to_keep)]\n",
    "#     return df_filtered\n",
    "\n",
    "# min_count 개 미만 클러스터 제거. 개선 버전\n",
    "def filter_clusters_with_min_count(cluster_labels, min_count=3):\n",
    "    for idx_cluster in range(cluster_labels.shape[1]):\n",
    "        cluster_counts = cluster_labels.iloc[:,idx_cluster].value_counts()\n",
    "        clusters_to_keep = cluster_counts[cluster_counts >= min_count].index\n",
    "        cluster_labels = cluster_labels[cluster_labels.iloc[:,idx_cluster].isin(clusters_to_keep)]\n",
    "    return cluster_labels\n",
    "\n",
    "# main 함수로 옮겨서 쓸 예정\n",
    "def make_cluster_labels_by_dataset(df):\n",
    "    rescaled_dataset = standard_scaler(df)\n",
    "    pca_labels = pca_kmeans_clustering(rescaled_dataset,5)\n",
    "    cosine_labels = cosine_kmeans_clustering(rescaled_dataset,5)\n",
    "\n",
    "    cluster_labels = pd.DataFrame()\n",
    "    cluster_labels.index = rescaled_dataset.index\n",
    "    cluster_labels['pca'] = pca_labels\n",
    "    cluster_labels['cosine'] = cosine_labels\n",
    "    cluster_labels = filter_clusters_with_min_count(cluster_labels)\n",
    "    return cluster_labels\n",
    "\n",
    "\n",
    "# load data\n",
    "# file = '../../data/krx_2016.csv'\n",
    "file = '../../data/krx_ta_2016.csv'\n",
    "# file_path = os.path.join(os.path.dirname(__file__), file)\n",
    "all_stocks = pd.read_csv(file, index_col=0)\n",
    "df = all_stocks.copy()\n",
    "# rescaled_dataset = standard_scaler(df)\n",
    "\n",
    "# pca_labels = pca_kmeans_clustering(rescaled_dataset,5)\n",
    "# cosine_labels = cosine_kmeans_clustering(rescaled_dataset,5)\n",
    "# cluster_labels = pd.DataFrame()\n",
    "# cluster_labels.index = rescaled_dataset.index\n",
    "# cluster_labels['pca'] = pca_labels\n",
    "# cluster_labels['cosine'] = cosine_labels\n",
    "\n",
    "# cluster_labels = filter_clusters_with_min_count(cluster_labels)\n",
    "cluster_labels = make_cluster_labels_by_dataset(df)\n",
    "print(cluster_labels)\n",
    "# cluster_counts = cluster_labels.iloc[:,0].value_counts()\n",
    "# # cluster_counts\n",
    "# clusters_to_keep = cluster_counts[cluster_counts.iloc[:,0] >= 3].index\n",
    "# clusters_to_keep\n",
    "# df_filtered = cluster_labels[cluster_labels.isin(clusters_to_keep)]\n",
    "# df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster_labels.shape[1])\n",
    "cluster_counts = cluster_labels.iloc[:,0].value_counts()\n",
    "clusters_to_keep = cluster_counts[cluster_counts >= 3].index\n",
    "df_filtered = cluster_labels[cluster_labels.iloc[:,0].isin(clusters_to_keep)]\n",
    "\n",
    "\n",
    "# df_filtered = df_filtered.dropna()\n",
    "print(df_filtered.shape)\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "# StandardScaler를 사용하여 데이터 표준화\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df.iloc[:, 1:])\n",
    "\n",
    "# PCA로 차원 축소\n",
    "pca = PCA(n_components=2)\n",
    "reduced_data = pca.fit_transform(scaled_data)\n",
    "\n",
    "# K-Means 클러스터링\n",
    "kmeans = KMeans(n_clusters=len(df['Name'].unique()), random_state=42)\n",
    "labels = kmeans.fit_predict(reduced_data)\n",
    "\n",
    "# 클러스터링 결과 시각화\n",
    "df['Cluster'] = labels\n",
    "colors = plt.cm.Spectral(df['Cluster'].astype(float) / len(df['Cluster'].unique()))\n",
    "plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=colors, edgecolor='k', s=40)\n",
    "plt.title('Cluster Visualization')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "\n",
    "# 각 점에 회사명 표시\n",
    "for company, x, y in zip(df['Name'], reduced_data[:, 0], reduced_data[:, 1]):\n",
    "    plt.text(x, y, company)\n",
    "\n",
    "plt.show()\n",
    "print(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample\n",
    "start_date = '20231201'\n",
    "end_date = '20231205'\n",
    "code = '005930'\n",
    "name = '삼성전자'\n",
    "df = get_dataset(code, name, start_date, end_date)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(stock_code, stock_name, start_date, end_date):\n",
    "    stock_df = fdr.DataReader(stock_code, start_date, end_date).reset_index()\n",
    "    stock_df['Name'] = stock_name\n",
    "    return stock_df\n",
    "def add_technical_indicators(stock_df):\n",
    "    ma = [5,20,60,120]\n",
    "    for days in ma:\n",
    "        stock_df['ma_'+str(days)] = stock_df['Close'].rolling(window = days).mean()\n",
    "    H, L, C, V = stock_df['High'], stock_df['Low'], stock_df['Close'], stock_df['Volume']\n",
    "\n",
    "    stock_df['RSI'] = ta.momentum.rsi(close=C, fillna=True)\n",
    "    stock_df['MACD'] = ta.trend.macd(close=C, fillna=True)\n",
    "    stock_df['-VI'] = ta.trend.vortex_indicator_neg(high=H, low=L, close=C, fillna=True)\n",
    "    stock_df['+VI'] = ta.trend.vortex_indicator_pos(high=H, low=L, close=C, fillna=True)\n",
    "    return stock_df\n",
    "\n",
    "# # 샘플 데이터 생성\n",
    "# start_date = '2023-11-01'\n",
    "# end_date = '2023-12-05'\n",
    "# kospi_list = pd.DataFrame({\n",
    "#     'Code': ['005930', '373220', '000660'],\n",
    "#     'Name': ['삼성전자', 'LG에너지솔루션', 'SK하이닉스']\n",
    "# })\n",
    "start_date = '20231101'\n",
    "end_date = '20231130'\n",
    "kospi = fdr.StockListing('KOSPI')\n",
    "kospi_list = kospi[['Code', 'Name']][:20]\n",
    "\n",
    "all_stocks = pd.DataFrame()\n",
    "\n",
    "# 데이터 수집 및 기술적 지표 추가\n",
    "for code, name in zip(kospi_list['Name'], kospi_list['Code']):\n",
    "    stock = get_dataset(name, code, start_date, end_date)\n",
    "    stock = add_technical_indicators(stock)\n",
    "    all_stocks = pd.concat([all_stocks, stock], ignore_index=True)\n",
    "\n",
    "# Pivot 데이터 구성\n",
    "features = all_stocks.columns.drop(['Name', 'Date'])\n",
    "pivot_stocks = all_stocks.pivot(index='Date', columns='Name', values=features)\n",
    "pivot_stocks = pivot_stocks.interpolate()\n",
    "\n",
    "# NaN 값을 0으로 대체\n",
    "pivot_stocks = pivot_stocks.fillna(0)\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "pivot_stocks_scaled = scaler.fit_transform(pivot_stocks)\n",
    "\n",
    "# PCA를 사용하여 데이터 차원 축소\n",
    "pca = PCA(n_components=2)\n",
    "pivot_stocks_pca = pca.fit_transform(pivot_stocks_scaled)\n",
    "\n",
    "# DBSCAN을 사용한 클러스터링\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=2)\n",
    "labels = dbscan.fit_predict(pivot_stocks_pca)\n",
    "\n",
    "print(labels)\n",
    "# # 종목별 클러스터 결과 저장\n",
    "# all_stocks['Cluster'] = labels\n",
    "\n",
    "# # 종목별 클러스터링 결과 시각화\n",
    "# for name, group in all_stocks.groupby('Name'):\n",
    "#     plt.figure(figsize=(8, 5))\n",
    "#     for cluster_label in set(group['Cluster']):\n",
    "#         cluster_data = group[group['Cluster'] == cluster_label]\n",
    "#         plt.scatter(cluster_data['Date'], cluster_data['Close'], label=f'Cluster {cluster_label}')\n",
    "\n",
    "#     plt.title(f'Clustering Result for {name}')\n",
    "#     plt.xlabel('Date')\n",
    "#     plt.ylabel('Close Price')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '20231201'\n",
    "end_date = '20231205'\n",
    "\n",
    "all_stocks = pd.DataFrame()\n",
    "stock = get_dataset('005930', '삼성전자',start_date, end_date)\n",
    "stock = add_technical_indicators(stock)\n",
    "stock1 = get_dataset('373220', 'LG에너지솔루션', start_date, end_date)\n",
    "stock1 = add_technical_indicators(stock1)\n",
    "all_stocks = pd.concat([all_stocks, stock], ignore_index=True)\n",
    "all_stocks = pd.concat([all_stocks, stock1], ignore_index=True)\n",
    "\n",
    "# for code, name in zip(data_list['Code'], data_list['Name']):\n",
    "#     tmp = get_dataset(code, start_date, end_date)\n",
    "#     tmp = add_technical_indicators(tmp)\n",
    "features = all_stocks.columns.drop(['Name'])\n",
    "\n",
    "# print(all_stocks.shape)\n",
    "# print(all_stocks)\n",
    "\n",
    "pivot_stocks = all_stocks.pivot(index='Date', columns='Name', values=features)\n",
    "pivot_stocks = pivot_stocks.interpolate()\n",
    "print(pivot_stocks)\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(pivot_stocks)\n",
    "\n",
    "# PCA를 사용하여 데이터 차원 축소\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# DBSCAN을 사용한 클러스터링\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=2)  # eps는 이웃을 결정하는 반경, min_samples는 클러스터가 될 최소 데이터 수\n",
    "labels = dbscan.fit_predict(X_pca)\n",
    "\n",
    "# 클러스터링 결과를 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for label in set(labels):\n",
    "    plt.scatter(X_pca[labels == label, 0], X_pca[labels == label, 1], label=f'Cluster {label}')\n",
    "\n",
    "plt.title('DBSCAN Clustering of Stock Data with Technical Indicators')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "# 필요한 특징 선택\n",
    "features = df[['Open', 'High', 'Low', 'Close', 'Volume', 'Change', 'ma_5', 'ma_20', 'ma_60', 'ma_120', 'RSI', 'MACD', '-VI', '+VI']]\n",
    "\n",
    "# 표준화 (Standardization)\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# DTW 거리 계산 함수\n",
    "def dtw_distance(series1, series2):\n",
    "    distance, path = fastdtw(series1, series2, dist=euclidean)\n",
    "    return distance\n",
    "\n",
    "# DTW 거리 행렬 생성\n",
    "dtw_matrix = pd.DataFrame(index=features.index, columns=features.index)\n",
    "for i in features.index:\n",
    "    for j in features.index:\n",
    "        dtw_matrix.at[i, j] = dtw_distance(features_scaled[i], features_scaled[j])\n",
    "\n",
    "# K-Means 클러스터링\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "df['Cluster'] = kmeans.fit_predict(dtw_matrix)\n",
    "\n",
    "# 클러스터링 결과 시각화\n",
    "plt.scatter(features['Date'], features['Close'], c=df['Cluster'], cmap='viridis')\n",
    "plt.title('Stock Clustering based on DTW Distance')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13개의 회사, 50일치 데이터\n",
    "num_companies = 13\n",
    "num_days = 50\n",
    "num_features = 6\n",
    "\n",
    "data = np.random.rand(num_companies, num_days, num_features)\n",
    "columns = ['Open', 'High', 'Low', 'Close', 'Volume', 'Change']\n",
    "companies = [f'Company_{i}' for i in range(num_companies)]\n",
    "\n",
    "# 임의의 주가 패턴 추가\n",
    "for i in range(num_companies):\n",
    "    data[i, :, :] += np.linspace(0, i * 0.1, num_days).reshape(-1, 1)\n",
    "\n",
    "df = pd.DataFrame(data.reshape(-1, num_features), columns=columns)\n",
    "df['Company'] = [companies[i] for i in range(num_companies) for _ in range(num_days)]\n",
    "df['Date'] = np.tile(pd.date_range(start='2022-01-01', periods=num_days), num_companies)\n",
    "\n",
    "df_pivot = df.pivot(index='Company', columns='Date', values=columns)\n",
    "\n",
    "print(df_pivot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average annual percentage return and volatilities over a theoretical one year period\n",
    "days = df.shape[0]\n",
    "returns = df.pct_change().mean() * days\n",
    "returns = pd.DataFrame(returns)\n",
    "returns.columns = ['Returns']\n",
    "returns['Volatility'] = df.pct_change().std() * np.sqrt(days)\n",
    "data=returns\n",
    "# format the data as a numpy array to feed into the K-Means algorithm\n",
    "# data = np.asarray([np.asarray(returns['Returns']),np.asarray(returns['Volatility'])]).T \n",
    "\n",
    "scaler = StandardScaler().fit(data)\n",
    "rescaledDataset = pd.DataFrame(scaler.fit_transform(data),columns = data.columns, index = data.index)\n",
    "# summarize transformed data\n",
    "rescaledDataset.head(2)\n",
    "X=rescaledDataset\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기술적 지표를 기반으로 정규화\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "\n",
    "# DBSCAN for Time Series\n",
    "dbscan = DBSCAN(metric='euclidean', eps=0.5, min_samples=5)\n",
    "df['DBSCAN_Labels'] = dbscan.fit_predict(df_scaled)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
